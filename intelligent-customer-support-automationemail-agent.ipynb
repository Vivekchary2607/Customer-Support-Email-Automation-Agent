{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI-Powered Customer Support Automation Email Agent\n\n## Problem Statement\n\nIn e-commerce, customers often send emails or chat queries regarding refunds, EMI options, shipping delays, account issues, or technical problems. \n\nManual customer support is:\n- Slow and inconsistent\n- Error-prone\n- Lacks personalization\n\nOur goal is to **automate email responses** with an intelligent AI agent that can:\n- Understand the intent behind queries\n- Detect emotional tone and urgency\n- Retrieve knowledge from internal knowledge bases and online sources\n- Draft high-quality, context-aware responses\n- Maintain multi-turn session memory for personalized interactions\n","metadata":{}},{"cell_type":"markdown","source":"## Solution & Innovation\n\nWe have built a **multi-agent AI system** to solve these challenges:\n\n- **Multi-Agent System:**\n  - `ResponseAgent` (drafts replies using Gemini LLM)\n  - `QAAgent` (reviews responses for quality)\n  - `ToneCheckerTool` (detects emotional tone and urgency)\n- **Knowledge Retrieval:**\n  - Internal KB using embeddings + TF-IDF\n  - Fallback to Google Search for missing information\n- **Customer Memory & Session:**\n  - Stores conversation history for multi-turn queries\n- **Custom Tools:**\n  - Product Info Tool for EMI, warranty, and product features\n\n**Innovation Highlights:**\n- Personalized automated responses\n- Real-time knowledge retrieval\n- Intelligent multi-agent orchestration\n- EMI calculation and explanation per product\n","metadata":{}},{"cell_type":"markdown","source":"# Importing The Necessary libraries ","metadata":{}},{"cell_type":"code","source":"# imports and secret loading (Kaggle-friendly)\nimport os\nimport json\nimport time\nfrom pathlib import Path\nfrom typing import List, Dict, Optional, Tuple\n\nimport numpy as np\nimport pandas as pd\n\n# ML libs\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load API key (Kaggle secrets preferred)\nGENAI_API_KEY = None\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    GENAI_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n    print(\"Loaded GENAI_API_KEY from Kaggle Secrets:\", GENAI_API_KEY is not None)\nexcept Exception:\n    GENAI_API_KEY = os.environ.get(\"GENAI_API_KEY\") or os.environ.get(\"GOOGLE_API_KEY\")\n    print(\"Loaded GENAI_API_KEY from env:\", GENAI_API_KEY is not None)\n\n# Try import Gemini SDK\nGENAI_SDK = False\ngenai = None\ntry:\n    import google.generativeai as genai\n    GENAI_SDK = True\n    print(\"google.generativeai SDK available.\")\nexcept Exception as e:\n    GENAI_SDK = False\n    genai = None\n    print(\"google.generativeai not available:\", e)\n\n# Final availability flag\nGENAI_AVAILABLE = GENAI_SDK and (GENAI_API_KEY is not None)\nprint(\"GENAI_AVAILABLE =\", GENAI_AVAILABLE)\n","metadata":{"execution":{"iopub.status.busy":"2025-11-17T05:33:20.498792Z","iopub.execute_input":"2025-11-17T05:33:20.499244Z","iopub.status.idle":"2025-11-17T05:33:20.562037Z","shell.execute_reply.started":"2025-11-17T05:33:20.499212Z","shell.execute_reply":"2025-11-17T05:33:20.560832Z"},"trusted":true},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\nLoaded GENAI_API_KEY from Kaggle Secrets: True\ngoogle.generativeai SDK available.\nGENAI_AVAILABLE = True\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# Initializing the GOOGLE_API_KEY","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nimport google.generativeai as genai\n\n# Load key\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"GOOGLE_API_KEY\")\n\n# Apply it\ngenai.configure(api_key=api_key)\n\nprint(\"Gemini API Ready\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:20.563519Z","iopub.execute_input":"2025-11-17T05:33:20.563810Z","iopub.status.idle":"2025-11-17T05:33:20.623097Z","shell.execute_reply.started":"2025-11-17T05:33:20.563786Z","shell.execute_reply":"2025-11-17T05:33:20.621946Z"}},"outputs":[{"name":"stdout","text":"Gemini API Ready\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Cell 3: Knowledge Base (use 'id', 'title', 'content')\nKB = [\n    {\"id\": \"kb1\", \"title\": \"Refund policy\", \"content\": \"Customers may request a refund within 30 days of purchase. Refunds are processed to the original payment method within 5 business days after approval.\"},\n    {\"id\": \"kb2\", \"title\": \"Billing issues\", \"content\": \"If double-charged, provide transaction ID and order number. We will investigate and process a refund if validated.\"},\n    {\"id\": \"kb3\", \"title\": \"Password reset\", \"content\": \"To reset your password go to /reset and follow the instructions. If you do not receive an email, check the spam folder or request a manual reset.\"},\n    {\"id\": \"kb4\", \"title\": \"Shipping delays\", \"content\": \"Shipments can be delayed due to carrier or weather. Typical delays are 3-7 days; provide order number to investigate.\"},\n    {\"id\": \"kb5\", \"title\": \"Order cancellation\", \"content\": \"Orders can be cancelled within 2 hours of placement. After that, cancellation may not be possible if shipping has started.\"},\n    {\"id\": \"kb6\", \"title\": \"Return instructions\", \"content\": \"To return an item, pack it securely and use the return label in your account. Returns must be postmarked within 30 days.\"},\n    {\"id\": \"kb7\", \"title\": \"Promo codes\", \"content\": \"Promo codes apply to eligible items only and cannot be combined. Check terms and expiry.\"},\n    {\"id\": \"kb8\", \"title\": \"Warranty\", \"content\": \"Products include a 1-year limited warranty covering manufacturing defects.\"},\n    {\"id\": \"kb9\", \"title\": \"Account verification\", \"content\": \"For security we may ask for order ID and the last 4 digits of the payment method.\"},\n    {\"id\": \"kb10\", \"title\": \"International shipping\", \"content\": \"International shipping may incur customs duties and longer transit times.\"},\n    {\"id\": \"kb11\",\"title\": \"EMI Options\",\n    \"content\": (\n        \"Customers can choose EMI options on eligible products. \"\n        \"EMI availability depends on bank, product, and purchase amount. \"\n        \"During checkout, the EMI options will be displayed with interest rates and tenure.\")},\n    {\"id\": \"kb12\",\"title\": \"Technical troubleshooting\",\"content\": \"If you experience errors, clear cache, restart the app, or contact support with error code details.\"},\n    {\"id\": \"kb13\",\"title\": \"Subscription plans\",\"content\": \"We offer monthly and yearly subscription plans. Upgrades can be done anytime via your account settings.\"},\n    {\"id\": \"kb14\", \"title\": \"Subscription plans\",\"content\": \"We offer monthly and yearly subscription plans. Upgrades can be done anytime via your account settings.\"}\n]\nprint(\"Loaded KB entries:\", len(KB))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:20.624166Z","iopub.execute_input":"2025-11-17T05:33:20.624497Z","iopub.status.idle":"2025-11-17T05:33:20.633017Z","shell.execute_reply.started":"2025-11-17T05:33:20.624468Z","shell.execute_reply":"2025-11-17T05:33:20.631891Z"}},"outputs":[{"name":"stdout","text":"Loaded KB entries: 14\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Cell 4: classifier training (demo synthetic data)\nLABELED = [\n    (\"I want a refund for my purchase\", \"refund\"),\n    (\"I was charged twice on my credit card\", \"billing\"),\n    (\"How do I reset my password\", \"technical\"),\n    (\"My package has not arrived\", \"shipping\"),\n    (\"When will my order be delivered\", \"shipping\"),\n    (\"I need to return the item\", \"refund\"),\n    (\"There is an unexpected charge on my invoice\", \"billing\"),\n    (\"I cannot login to my account\", \"technical\"),\n]\n\ntexts = [t for t, _ in LABELED]\nlabels = [l for _, l in LABELED]\n\nvectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=2000)\nX = vectorizer.fit_transform(texts)\nclf = LogisticRegression(max_iter=1000)\nclf.fit(X, labels)\n\ndef predict_label(text: str) -> str:\n    x = vectorizer.transform([text])\n    return clf.predict(x)[0]\n\nprint(\"Classifier trained.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:20.634562Z","iopub.execute_input":"2025-11-17T05:33:20.634832Z","iopub.status.idle":"2025-11-17T05:33:20.662745Z","shell.execute_reply.started":"2025-11-17T05:33:20.634808Z","shell.execute_reply":"2025-11-17T05:33:20.661689Z"}},"outputs":[{"name":"stdout","text":"Classifier trained.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# EmbeddingSearch","metadata":{}},{"cell_type":"code","source":"# EmbeddingSearch (tries supported models and falls back to TF-IDF)\nclass EmbeddingSearch:\n    def __init__(self, kb: List[Dict], try_models: Optional[List[str]] = None):\n        self.kb = kb\n        self.texts = [d[\"content\"] for d in kb]\n        self.ids = [d[\"id\"] for d in kb]\n        self.kb_embeddings = None\n\n        # TF-IDF prepared always as fallback\n        self.tfidf = TfidfVectorizer().fit(self.texts + [d[\"title\"] for d in kb])\n        self.tfidf_matrix = self.tfidf.transform(self.texts)\n\n        if try_models is None:\n            # model names to try (adjust if your account uses different names)\n            try_models = [\"gemini-embedding-001\", \"text-embedding-004\", \"text-embedding-003\"]\n\n        if GENAI_AVAILABLE:\n            try:\n                genai.configure(api_key=GENAI_API_KEY)\n            except Exception as e:\n                print(\"Warning: genai.configure failed:\", e)\n\n            for model_name in try_models:\n                try:\n                    print(f\"[EmbeddingSearch] Trying model: {model_name}\")\n                    emb_list = []\n                    for txt in self.texts:\n                        resp = genai.embed_content(model=model_name, content=txt)\n                        # robust extraction\n                        emb = None\n                        if isinstance(resp, dict) and \"embedding\" in resp:\n                            emb = np.array(resp[\"embedding\"], dtype=\"float32\")\n                        elif hasattr(resp, \"embedding\"):\n                            emb = np.array(resp.embedding, dtype=\"float32\")\n                        elif isinstance(resp, dict) and \"embeddings\" in resp:\n                            emb = np.array(resp[\"embeddings\"][0], dtype=\"float32\")\n                        elif hasattr(resp, \"embeddings\"):\n                            emb_obj = resp.embeddings[0]\n                            if hasattr(emb_obj, \"values\"):\n                                emb = np.array(list(emb_obj.values), dtype=\"float32\")\n                            elif hasattr(emb_obj, \"embedding\"):\n                                emb = np.array(emb_obj.embedding, dtype=\"float32\")\n                        if emb is None:\n                            emb = np.random.rand(768).astype(\"float32\")\n                        emb_list.append(emb)\n                    self.kb_embeddings = np.vstack(emb_list)\n                    self.embedding_model_used = model_name\n                    print(f\"[EmbeddingSearch] Success with {model_name}, shape = {self.kb_embeddings.shape}\")\n                    break\n                except Exception as e:\n                    print(f\"[EmbeddingSearch] Model {model_name} failed: {e}\")\n                    self.kb_embeddings = None\n                    continue\n            if self.kb_embeddings is None:\n                print(\"[EmbeddingSearch] All embedding attempts failed — TF-IDF will be used.\")\n        else:\n            print(\"[EmbeddingSearch] GENAI not available — using TF-IDF only.\")\n\n    def _embed_query(self, query: str) -> Optional[np.ndarray]:\n        if not GENAI_AVAILABLE or self.kb_embeddings is None:\n            return None\n        try:\n            resp = genai.embed_content(model=self.embedding_model_used, content=query)\n            if isinstance(resp, dict) and \"embedding\" in resp:\n                return np.array(resp[\"embedding\"], dtype=\"float32\")\n            elif hasattr(resp, \"embedding\"):\n                return np.array(resp.embedding, dtype=\"float32\")\n            elif isinstance(resp, dict) and \"embeddings\" in resp:\n                return np.array(resp[\"embeddings\"][0], dtype=\"float32\")\n            elif hasattr(resp, \"embeddings\"):\n                emb_obj = resp.embeddings[0]\n                if hasattr(emb_obj, \"values\"):\n                    return np.array(list(emb_obj.values), dtype=\"float32\")\n                elif hasattr(emb_obj, \"embedding\"):\n                    return np.array(emb_obj.embedding, dtype=\"float32\")\n            return None\n        except Exception as e:\n            print(\"Query embedding failed:\", e)\n            return None\n\n    def search(self, query: str, top_k: int = 3) -> List[Dict]:\n        # Embedding path\n        if self.kb_embeddings is not None:\n            q_emb = self._embed_query(query)\n            if q_emb is not None:\n                sims = cosine_similarity([q_emb], self.kb_embeddings).squeeze()\n                idx = sims.argsort()[-top_k:][::-1]\n                return [self.kb[i] for i in idx]\n        # TF-IDF fallback\n        qv = self.tfidf.transform([query])\n        sims = (self.tfidf_matrix @ qv.T).toarray().squeeze()\n        idx = sims.argsort()[-top_k:][::-1]\n        return [self.kb[i] for i in idx]\n\n# initialize\nembedding_search = EmbeddingSearch(KB)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:20.673652Z","iopub.execute_input":"2025-11-17T05:33:20.674037Z","iopub.status.idle":"2025-11-17T05:33:22.839056Z","shell.execute_reply.started":"2025-11-17T05:33:20.674001Z","shell.execute_reply":"2025-11-17T05:33:22.837733Z"}},"outputs":[{"name":"stdout","text":"[EmbeddingSearch] Trying model: gemini-embedding-001\n[EmbeddingSearch] Success with gemini-embedding-001, shape = (14, 3072)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"class GeminiLLM:\n    def __init__(self, model_name=\"gemini-2.5-flash-lite\"):\n        # use the already-configured genai client\n        self.model = genai.GenerativeModel(model_name)\n\n    def generate(self, prompt, max_output_tokens=256):\n        try:\n            response = self.model.generate_content(\n                prompt,\n                generation_config={\"max_output_tokens\": max_output_tokens}\n            )\n            return response.text\n        except Exception as e:\n            raise RuntimeError(f\"Gemini generation failed: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:22.840514Z","iopub.execute_input":"2025-11-17T05:33:22.840890Z","iopub.status.idle":"2025-11-17T05:33:22.847385Z","shell.execute_reply.started":"2025-11-17T05:33:22.840865Z","shell.execute_reply":"2025-11-17T05:33:22.846079Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# context compaction helper Function","metadata":{}},{"cell_type":"code","source":"#  # context compaction helper\ndef compact_context(customer_memory: Dict, session_history: str, kb_texts: List[str], max_len_chars: int = 3000) -> str:\n    parts = []\n    if session_history:\n        parts.append(\"Session History:\\n\" + session_history[-1500:])\n    if customer_memory:\n        mem_items = [f\"{k}: {v}\" for k, v in customer_memory.items() if k != \"last_response\"]\n        if mem_items:\n            parts.append(\"Customer Memory:\\n\" + \"\\n\".join(mem_items))\n    if kb_texts:\n        parts.append(\"KB Summary:\\n\" + \"\\n\".join(kb_texts[:3]))\n    ctx = \"\\n\\n\".join(parts)\n    if len(ctx) > max_len_chars:\n        ctx = ctx[-max_len_chars:]\n    return ctx\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:22.848457Z","iopub.execute_input":"2025-11-17T05:33:22.848711Z","iopub.status.idle":"2025-11-17T05:33:22.855957Z","shell.execute_reply.started":"2025-11-17T05:33:22.848688Z","shell.execute_reply":"2025-11-17T05:33:22.854909Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"#  ResponseAgent, QAAgent, Memory","metadata":{}},{"cell_type":"code","source":"# ResponseAgent, QAAgent, Memory\nclass ResponseAgent:\n    def __init__(self, llm_obj: GeminiLLM, embedding_search_obj: EmbeddingSearch):\n        self.llm = llm_obj\n        self.embedding_search = embedding_search_obj\n\n    def draft(self, customer: Dict, email_text: str, kb_results: List[Dict], session_context: Optional[Dict] = None) -> Dict:\n        cust_summary = \"\"\n        if customer:\n            parts = [f\"{k}: {v}\" for k, v in customer.items() if k != \"last_response\"]\n            cust_summary = \"\\n\".join(parts)\n        # also retrieve from embedding search (RAG)\n        retrieved = self.embedding_search.search(email_text, top_k=3)\n        retrieved_text = \"\\n\".join([f\"- {r['title']}: {r['content']}\" for r in retrieved]) if retrieved else \"None\"\n        kb_summary = \"\\n\".join([f\"- {d['title']}\" for d in kb_results]) if kb_results else \"None\"\n        compacted = compact_context(customer, session_context or \"\", [d[\"content\"] for d in retrieved])\n\n        prompt = f\"\"\"\nYou are an expert, concise and polite customer support assistant.\n\nCustomer summary:\n{cust_summary}\n\nCustomer message:\n{email_text}\n\nTop KB (titles):\n{kb_summary}\n\nVector retrieved passages:\n{retrieved_text}\n\nCompacted context:\n{compacted}\n\nWrite a concise, polite, and fully grounded customer support reply. Use only the information from the KB or the customer's message. If you need more info, ask a single clarifying question.\n\"\"\"\n        # generate via Gemini\n        reply = self.llm.generate(prompt)\n         # Ensure signoff is included\n        if \"regards\" not in reply.lower() and \"best\" not in reply.lower() and \"support team\" not in reply.lower():\n            reply += \"\\n\\nRegards,\\nSupport Team\"\n        return {\"reply\": reply, \"prompt\": prompt, \"retrieved\": retrieved}\n\nclass QAAgent:\n    def review(self, draft_text: str) -> Dict:\n        issues = []\n        if len(draft_text.split()) < 8:\n            issues.append(\"reply too short\")\n        if not any(s in draft_text.lower() for s in [\"regards\", \"Regards\",\"best\", \"support team\"]):\n            issues.append(\"missing signoff\")\n        return {\"issues\": issues, \"approved\": len(issues) == 0}\n\nclass CustomerMemory:\n    def __init__(self, path: str = \"./customer_memory.json\"):\n        self.path = Path(path)\n        if self.path.exists():\n            try:\n                self.data = json.loads(self.path.read_text())\n            except Exception:\n                self.data = {}\n        else:\n            self.data = {}\n\n    def get(self, customer_id: str) -> Dict:\n        return self.data.get(customer_id, {})\n\n    def update(self, customer_id: str, info: Dict):\n        self.data.setdefault(customer_id, {}).update(info)\n        self.path.write_text(json.dumps(self.data, indent=2))\n\nclass SessionMemory:\n    def __init__(self):\n        self.store = {}\n\n    def add(self, session_id: str, message: str):\n        self.store.setdefault(session_id, []).append(message)\n\n    def get(self, session_id: str, last_n: int = 5) -> str:\n        return \"\\n\".join(self.store.get(session_id, [])[-last_n:])\n\nprint(\"Agents and memory ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:22.857458Z","iopub.execute_input":"2025-11-17T05:33:22.858171Z","iopub.status.idle":"2025-11-17T05:33:22.875064Z","shell.execute_reply.started":"2025-11-17T05:33:22.858144Z","shell.execute_reply":"2025-11-17T05:33:22.874041Z"}},"outputs":[{"name":"stdout","text":"Agents and memory ready.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"# Session Memory","metadata":{}},{"cell_type":"code","source":"class SessionStore:\n    def __init__(self):\n        self.sessions = {}\n\n    def get(self, session_id):\n        return self.sessions.get(session_id, {\"history\": []})\n\n    def save(self, session_id, state):\n        self.sessions[session_id] = state\n\n\nsession_store = SessionStore()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:22.877579Z","iopub.execute_input":"2025-11-17T05:33:22.877861Z","iopub.status.idle":"2025-11-17T05:33:22.883697Z","shell.execute_reply.started":"2025-11-17T05:33:22.877840Z","shell.execute_reply":"2025-11-17T05:33:22.882636Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"# Custom Tool (ToneCheckerTool)","metadata":{}},{"cell_type":"code","source":"class ToneCheckerTool:\n    def analyze(self, text):\n        text = text.lower()\n        flags = []\n\n        if \"angry\" in text or \"frustrated\" in text:\n            flags.append(\"customer emotional tone detected\")\n\n        if \"urgent\" in text or \"immediately\" in text:\n            flags.append(\"urgent context detected\")\n\n        return {\"tone_flags\": flags}\n\ntone_tool = ToneCheckerTool()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:22.884599Z","iopub.execute_input":"2025-11-17T05:33:22.884892Z","iopub.status.idle":"2025-11-17T05:33:22.890294Z","shell.execute_reply.started":"2025-11-17T05:33:22.884863Z","shell.execute_reply":"2025-11-17T05:33:22.889264Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"# Observability (Logging + Trace IDs)","metadata":{}},{"cell_type":"code","source":"import uuid, time\n\ndef log_event(event_type, data):\n    trace_id = str(uuid.uuid4())[:8]\n    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:22.891450Z","iopub.execute_input":"2025-11-17T05:33:22.891829Z","iopub.status.idle":"2025-11-17T05:33:22.896925Z","shell.execute_reply.started":"2025-11-17T05:33:22.891803Z","shell.execute_reply":"2025-11-17T05:33:22.895684Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## Architecture Diagram\n\nThe system architecture of the AI Customer Support Agent is as follows:\n\n        +-----------------+\n        |  Customer Email |\n        +--------+--------+\n                 |\n                 v\n       +-------------------+\n       |  Logging / Tracing |\n       +-------------------+\n                 |\n                 v\n       +-------------------+\n       | Tone Detection    |\n       | (ToneCheckerTool) |\n       +-------------------+\n                 |\n                 v\n       +-------------------+\n       | Intent Classification |\n       |   (TF-IDF / ML)       |\n       +-------------------+\n                 |\n                 v\n       +-------------------+\n       | Knowledge Retrieval |\n       |  (KB + Google)     |\n       +-------------------+\n                 |\n                 v\n       +-------------------+\n       | Response Drafting |\n       |   (Gemini LLM)   |\n       +-------------------+\n                 |\n                 v\n       +-------------------+\n       | Quality Review    |\n       |   (QAAgent)       |\n       +-------------------+\n                 |\n                 v\n       +-------------------+\n       | Customer Memory   |\n       |  Update & Session |\n       +-------------------+\n                 |\n                 v\n       +-------------------+\n       | Customer Response |\n       +-------------------+\n","metadata":{}},{"cell_type":"markdown","source":"# Orchestration process","metadata":{}},{"cell_type":"code","source":"# orchestrator_process (uses embedding_search.search)\ndef orchestrator_process(\n    email: Dict,\n    classifier_predict,\n    search_tool: EmbeddingSearch,\n    memory: CustomerMemory,\n    response_agent: ResponseAgent,\n    qa_agent: QAAgent\n):\n    session_id = email[\"customer_id\"]\n    log_event(\"email_received\", email)\n    tone_result = tone_tool.analyze(email[\"text\"])\n    \n    # 1) classify\n    category = classifier_predict(email[\"text\"])\n    #log_event(\"tone_detected\", {\"category\": category})\n\n    # 2) retrieve KB via embeddings (best) or TF-IDF fallback\n    kb_hits = search_tool.search(email[\"text\"], top_k=3)\n    #log_event(\"kb_search\", {\"hits\": [d[\"id\"] for d in kb_hits]})\n    # 3) session/memory\n    cust = memory.get(email[\"customer_id\"])\n\n    # 4) draft response using response_agent (which calls Gemini)\n    drafted = response_agent.draft(cust, email[\"text\"], kb_hits)\n\n    # 5) quality review\n    qa = qa_agent.review(drafted[\"reply\"])\n\n    # 6) update memory\n    memory.update(email[\"customer_id\"], {\n        \"last_category\": category,\n        \"last_response\": drafted[\"reply\"][:300],\n        \"updated_at\": time.time()\n    })\n    # Save session\n    state = session_store.get(session_id)\n    state[\"history\"].append(email[\"text\"])\n    session_store.save(session_id, state)\n    return {\n        \"email_id\": email.get(\"id\") or email.get(\"email_id\"),\n        \"customer_id\": email[\"customer_id\"],\n        \"text\": email[\"text\"],\n        \"predicted_category\": category,\n        \"kb_hits\": [d[\"id\"] for d in kb_hits],\n        \"retrieved\": [r[\"id\"] for r in drafted.get(\"retrieved\", [])],\n        \"reply\": drafted[\"reply\"],\n        \"qa_approved\": qa[\"approved\"],\n        \"qa_issues\": qa[\"issues\"],\n    }\n\nprint(\"Orchestrator ready.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:22.898054Z","iopub.execute_input":"2025-11-17T05:33:22.898397Z","iopub.status.idle":"2025-11-17T05:33:22.908785Z","shell.execute_reply.started":"2025-11-17T05:33:22.898365Z","shell.execute_reply":"2025-11-17T05:33:22.907469Z"}},"outputs":[{"name":"stdout","text":"Orchestrator ready.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## Agent Workflow\n\n1. **Email Received**\n    - Log the email and generate a trace ID\n2. **Tone Analysis**\n    - Detect if customer is angry or urgent\n3. **Intent Classification**\n    - Predict category (refund, shipping, technical, product info)\n4. **Knowledge Retrieval**\n    - Search internal KB\n    - If KB fails, perform Google Search\n5. **Response Drafting**\n    - Draft response using Gemini LLM\n6. **Quality Review**\n    - QAAgent checks response quality\n7. **Update Memory**\n    - Save last response, category, and conversation history\n8. **Send Reply**\n    - Reply returned to customer\n","metadata":{}},{"cell_type":"markdown","source":"# Agent Responses","metadata":{}},{"cell_type":"code","source":"# demo run pipeline\nmemory = CustomerMemory(path=\"./customer_memory.json\")\nsession_memory = SessionMemory()\nllm=GeminiLLM()\nresponse_agent = ResponseAgent(llm, embedding_search)\nqa_agent = QAAgent()\n\nSAMPLE_EMAILS = [\n    {\"id\": \"e1\", \"customer_id\": \"c234\", \"text\": \"I can't reset my password. The reset link is not working.\"},\n    {\"id\": \"e2\", \"customer_id\": \"c345\", \"text\": \"My shipment is late. Where is my package?\"},\n    {\"id\": \"e3\", \"customer_id\": \"c456\", \"text\": \"How long is your refund policy? I returned the item last week.\"},\n]\n\nresults = []\nfor e in SAMPLE_EMAILS:\n    out = orchestrator_process(e, predict_label, embedding_search, memory, response_agent, qa_agent)\n    results.append(out)\n\ndf = pd.DataFrame(results)\ndisplay(df[[\"email_id\", \"customer_id\", \"predicted_category\", \"kb_hits\", \"retrieved\", \"qa_approved\"]])\n\nprint(\"\\n--- Example reply (email e1) ---\\n\")\nprint(results[2][\"reply\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:22.909413Z","iopub.execute_input":"2025-11-17T05:33:22.909633Z","iopub.status.idle":"2025-11-17T05:33:25.524439Z","shell.execute_reply.started":"2025-11-17T05:33:22.909615Z","shell.execute_reply":"2025-11-17T05:33:25.523319Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  email_id customer_id predicted_category           kb_hits         retrieved  \\\n0       e1        c234          technical  [kb3, kb12, kb9]  [kb3, kb12, kb9]   \n1       e2        c345           shipping  [kb4, kb10, kb5]  [kb4, kb10, kb5]   \n2       e3        c456             refund   [kb1, kb6, kb4]   [kb1, kb6, kb4]   \n\n   qa_approved  \n0         True  \n1         True  \n2         True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>email_id</th>\n      <th>customer_id</th>\n      <th>predicted_category</th>\n      <th>kb_hits</th>\n      <th>retrieved</th>\n      <th>qa_approved</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>e1</td>\n      <td>c234</td>\n      <td>technical</td>\n      <td>[kb3, kb12, kb9]</td>\n      <td>[kb3, kb12, kb9]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>e2</td>\n      <td>c345</td>\n      <td>shipping</td>\n      <td>[kb4, kb10, kb5]</td>\n      <td>[kb4, kb10, kb5]</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>e3</td>\n      <td>c456</td>\n      <td>refund</td>\n      <td>[kb1, kb6, kb4]</td>\n      <td>[kb1, kb6, kb4]</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n--- Example reply (email e1) ---\n\nOur refund policy allows for refunds within 30 days of purchase. Once approved, refunds are typically processed to your original payment method within 5 business days. Since you returned the item last week, your refund should be processed shortly.\n\nRegards,\nSupport Team\n","output_type":"stream"}],"execution_count":31},{"cell_type":"markdown","source":"# Testing the agent on various user inputs to understand how the agents will response on different situations and give effective feedback","metadata":{}},{"cell_type":"code","source":"TEST_EMAILS = [ {\n  \"id\": \"1\",\n  \"customer_id\": \"cx401\",\n  \"text\": \"I ordered something last week—I think it was the earbuds, but I'm not fully sure because I had multiple items in my cart—and now I can't tell whether the actual product shipped or if only the accessory shipped first. The tracking shows 'in transit' but the weight seems incorrect. Can you verify everything?\"\n},\n{\n  \"id\": \"2\",\n  \"customer_id\": \"c115\",\n  \"text\": \"I want to purchase 50 units of your product for an event. Do you offer any bulk discount?\"\n},\n{\n  \"id\": \"3\",\n  \"customer_id\": \"c114\",\n  \"text\": \"I placed an order yesterday but it is not showing under my 'My Orders' section.\"\n},\n{\n  \"id\": \"4\",\n  \"customer_id\": \"cx401\",\n  \"text\": \"I ordered something last week—I think it was the earbuds, but I'm not fully sure because I had multiple items in my cart—and now I can't tell whether the actual product shipped or if only the accessory shipped first. The tracking shows 'in transit' but the weight seems incorrect. Can you verify everything?\"\n},\n{\n  \"id\": \"5\",\n  \"customer_id\": \"cx402\",\n  \"text\": \"My app keeps crashing whenever I try to upload photos. I already tried reinstalling, clearing cache, and rebooting my phone but it still crashes.\"\n},\n{\n  \"id\": \"6\",\n  \"customer_id\": \"cx404\",\n  \"text\": \"Hello! I accidentally ordered two sets of the same dinnerware. I only need one. Could you please help me return the extra one? It's still sealed.\"\n}              \n ]\n\nfor e in TEST_EMAILS:\n    result = orchestrator_process(e, predict_label, embedding_search, memory, response_agent, qa_agent)\n    print(\"Email:\", e[\"id\"])\n    print(\"Reply:\", result[\"reply\"])\n    print(\"QA Approved:\", result[\"qa_approved\"])\n    print(\"------\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:25.525331Z","iopub.execute_input":"2025-11-17T05:33:25.525560Z","iopub.status.idle":"2025-11-17T05:33:30.275199Z","shell.execute_reply.started":"2025-11-17T05:33:25.525540Z","shell.execute_reply":"2025-11-17T05:33:30.274289Z"}},"outputs":[{"name":"stdout","text":"Email: 1\nReply: I understand you're concerned about your recent order and want to verify its contents and shipping status. To help me investigate this for you, could you please provide your order number?\n\nRegards,\nSupport Team\nQA Approved: True\n------\nEmail: 2\nReply: We do not offer specific bulk discounts. However, you can check for any active promo codes on eligible items.\n\nRegards,\nSupport Team\nQA Approved: True\n------\nEmail: 3\nReply: I understand your order isn't showing in your 'My Orders' section. Could you please provide your order number so I can investigate this for you?\n\nRegards,\nSupport Team\nQA Approved: True\n------\nEmail: 4\nReply: Hello! I can help you verify your order details. To investigate the shipment and the tracking information, could you please provide your order number?\n\nRegards,\nSupport Team\nQA Approved: True\n------\nEmail: 5\nReply: I understand you're experiencing app crashes when uploading photos, even after trying common troubleshooting steps. To help me investigate this further, could you please provide any specific error codes or messages that appear when the app crashes?\n\nRegards,\nSupport Team\nQA Approved: True\n------\nEmail: 6\nReply: Hello!\n\nI understand you'd like to return an extra set of dinnerware. To proceed with the return, please pack the item securely and use the return label available in your account. Please ensure the return is postmarked within 30 days.\n\nRegards,\nSupport Team\nQA Approved: True\n------\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"# Agent Evaluation","metadata":{}},{"cell_type":"code","source":"memory = CustomerMemory(path=\"./customer_memory.json\")\nsession_memory = SessionMemory()\nllm=GeminiLLM()\nresponse_agent = ResponseAgent(llm, embedding_search)\nqa_agent = QAAgent()\ntest_cases = [\n    {\n        \"email\": {\"text\": \"I am frustrated! I want refund immediately!\", \"customer_id\": \"c999\"},\n        \"expected\": [\"customer emotional tone detected\"]\n    },\n    {\n        \"email\": {\"text\": \"When will my order arrive?\", \"customer_id\": \"c222\"},\n        \"expected\": []\n    }\n]\n\ndef evaluate_agent():\n    results = []\n    for i, tc in enumerate(test_cases):\n        result = orchestrator_process(\n            email=tc[\"email\"],\n            classifier_predict=predict_label,\n            search_tool=embedding_search,\n            memory=memory,\n            response_agent=response_agent,\n            qa_agent=qa_agent\n        )\n        results.append(result)\n\n    return results\n\nevaluate_agent()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T05:33:30.276323Z","iopub.execute_input":"2025-11-17T05:33:30.276877Z","iopub.status.idle":"2025-11-17T05:33:31.819248Z","shell.execute_reply.started":"2025-11-17T05:33:30.276845Z","shell.execute_reply":"2025-11-17T05:33:31.818065Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[{'email_id': None,\n  'customer_id': 'c999',\n  'text': 'I am frustrated! I want refund immediately!',\n  'predicted_category': 'refund',\n  'kb_hits': ['kb1', 'kb6', 'kb5'],\n  'retrieved': ['kb1', 'kb6', 'kb5'],\n  'reply': \"I understand you're seeking an immediate refund. To process this, could you please provide your order number?\\n\\nRegards,\\nSupport Team\",\n  'qa_approved': True,\n  'qa_issues': []},\n {'email_id': None,\n  'customer_id': 'c222',\n  'text': 'When will my order arrive?',\n  'predicted_category': 'shipping',\n  'kb_hits': ['kb4', 'kb10', 'kb5'],\n  'retrieved': ['kb4', 'kb10', 'kb5'],\n  'reply': 'I can help you with that. To check the status of your order, could you please provide your order number?\\n\\nRegards,\\nSupport Team',\n  'qa_approved': True,\n  'qa_issues': []}]"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}